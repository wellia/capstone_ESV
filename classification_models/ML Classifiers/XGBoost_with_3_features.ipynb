{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost_with_3_features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bXYVC5LXTkA2",
        "outputId": "15e9c1df-521a-4559-ea25-304be03de82f"
      },
      "source": [
        "import pandas as pd\r\n",
        "import nltk\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import accuracy_score, classification_report\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.model_selection import GridSearchCV \r\n",
        "\r\n",
        "import nltk \r\n",
        "from nltk.corpus import stopwords\r\n",
        "import re\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\r\n",
        "import pickle\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting texthero\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/5a/a9d33b799fe53011de79d140ad6d86c440a2da1ae8a7b24e851ee2f8bde8/texthero-1.0.9-py3-none-any.whl\n",
            "Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.5.0)\n",
            "Requirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.18.5)\n",
            "Collecting unidecode>=1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.1MB/s \n",
            "\u001b[?25hCollecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (4.4.1)\n",
            "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from texthero) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (3.2.2)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from texthero) (2.2.4)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.6/dist-packages (from texthero) (4.41.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud>=1.5.0->texthero) (7.0.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.6.0->texthero) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.6.0->texthero) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.6.0->texthero) (1.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (0.17.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (2019.12.20)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.2->texthero) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (3.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (50.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (2.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (0.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.4.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=4f02aacfa9c9bb5ed1668143e36b11bc42d340439a2816991c5a624d5e2155a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: unidecode, nltk, texthero\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5 texthero-1.0.9 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RPDt9pqVU0s"
      },
      "source": [
        "# Creating a list for columns to keep\r\n",
        "cols = ['EventDescription','IncidentCause','IncidentConsequence', 'Category']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbZVfh5MVmnx",
        "outputId": "e5491046-e5d8-4973-a76b-286d0278700e"
      },
      "source": [
        "# Importing file\r\n",
        "df = pd.read_csv('cleaned_incidents1.csv', usecols=cols)\r\n",
        "print(df.shape)\r\n",
        "\r\n",
        "#dropping nulls\r\n",
        "df = df.dropna()\r\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6504, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EventDescription       0\n",
              "IncidentCause          0\n",
              "IncidentConsequence    0\n",
              "Category               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beA-heykVrgG"
      },
      "source": [
        "df['Description'] = df['EventDescription'] + ' ' + df['IncidentCause'] + ' ' + df['IncidentConsequence']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SifYQfb_WjkZ",
        "outputId": "9cade9ca-4c1e-4064-ad5c-5a9ca53f7b21"
      },
      "source": [
        "print(df['Description'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       A nearby customer reported sparking of electri...\n",
            "1       A contractor reported that he had contacted an...\n",
            "2       A field crew attending an outage found that a ...\n",
            "3       Interfere and vandalism in substation. Unknown...\n",
            "4       A nearby customer reported that a high load ha...\n",
            "                              ...                        \n",
            "6499    A report came in to UE of a FMB sparking at 31...\n",
            "6500    Report received from a resident to advise that...\n",
            "6501    Report received of pole fire at incident locat...\n",
            "6502    A customer called to report a tractor had hit ...\n",
            "6503    concrete electrical cover outside of front of ...\n",
            "Name: Description, Length: 6488, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB231POiWn0N"
      },
      "source": [
        "Stopwords, Splitting, Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZdLOhsgWooZ"
      },
      "source": [
        "# Creating stopwords list\r\n",
        "\r\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\r\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\r\n",
        "numerical_symbols = re.compile('0-90-9a-z')\r\n",
        " \r\n",
        "STOPWORDS = set(stopwords.words('english'))\r\n",
        " \r\n",
        "def clean_text(text):\r\n",
        "    text = text.lower() # lowercase text\r\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\r\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \r\n",
        "    text = numerical_symbols.sub('', text)\r\n",
        "    text = text.replace('x', '')\r\n",
        "    #text = re.sub(r'\\W+', '', text)\r\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\r\n",
        "    return text\r\n",
        "\r\n",
        "df['Description'] = df['Description'].apply(clean_text)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B6mtjhVWzEA",
        "outputId": "3d89fd2a-c8e6-4d09-9514-48da78f4bcb7"
      },
      "source": [
        "print(df['Description'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       nearby customer reported sparking electrical l...\n",
            "1       contractor reported contacted earthing cable e...\n",
            "2       field crew attending outage found 22kv conduct...\n",
            "3       interfere vandalism substation unknown third p...\n",
            "4       nearby customer reported high load pulled wire...\n",
            "                              ...                        \n",
            "6499    report came ue fmb sparking 310 st kilda st br...\n",
            "6500    report received resident advise crane made con...\n",
            "6501    report received pole fire incident locationon ...\n",
            "6502    customer called report tractor hit wire brough...\n",
            "6503    concrete electrical cover outside front house ...\n",
            "Name: Description, Length: 6488, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60X7YqzhW2Iu"
      },
      "source": [
        "# Label encoding for Category\r\n",
        "le = LabelEncoder()\r\n",
        "df['Category'] = le.fit_transform(df['Category'].astype(str))\r\n",
        "#store the 'Category' variable in Y\r\n",
        "X = df[['Description']]\r\n",
        "Y = df[['Category']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDo982xAXz16"
      },
      "source": [
        "# Splitting of data in test and train\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['Description'],Y, \r\n",
        "                                                    test_size=0.25, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-5qNuR2X2GC"
      },
      "source": [
        "XGBoost with three features (Event Description, Incident Cause and Incident Consequence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kCpbRB9X9_c"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2mz4z9OYE3q"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords, analyzer='word', max_features=1000)\r\n",
        "tfidf = vectorizer.fit(df['Description'])\r\n",
        "# tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4xo2ZxIYIbG"
      },
      "source": [
        "x_train_tfidf =  tfidf.transform(x_train)\r\n",
        "x_test_tfidf =  tfidf.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L89ZEgdCYMsv"
      },
      "source": [
        "from xgboost import XGBClassifier\r\n",
        "clf = XGBClassifier(learning_rate=0.1, verbosity=2)\r\n",
        "clf.fit(x_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpFUkB83YTFl",
        "outputId": "c101b10b-61df-4bc8-f01f-4a7f04b222cb"
      },
      "source": [
        "# Model evaluation\r\n",
        "prediction = clf.predict(x_test_tfidf)\r\n",
        "\r\n",
        "acc = accuracy_score(y_test, prediction).round(4)\r\n",
        "print(\"Accuracy using TF-IDF is: {}%\".format(acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using TF-IDF is: 80.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7GPELje5bJeZ",
        "outputId": "1f88c925-3aa7-4510-e977-390ad596d0cb"
      },
      "source": [
        "# grid search\r\n",
        "param_grid = {\r\n",
        "    'learning_rate': [0.10, 0.20, 0.50],\r\n",
        "    'max_depth' : [3, 4],\r\n",
        "    'verbosity' : [1, 2],\r\n",
        "    'min_child_weight' :[1, 2],\r\n",
        "    # 'gamma' : [0.1, 0.2],\r\n",
        "    # 'colsample_bytree' : [0.3, 0.4, 0.5, 0.7]\r\n",
        "}\r\n",
        "cv_xgb = GridSearchCV(estimator=XGBClassifier(random_state=4),\r\n",
        "                      param_grid=param_grid, cv= 5, n_jobs=-1)\r\n",
        "cv_xgb.fit(x_train_tfidf, y_train)\r\n",
        "cv_xgb.best_params_\r\n",
        "print(cv_xgb.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8288107443056993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weOPtHmchEEv",
        "outputId": "4cfb7eab-4bd4-4c5c-9919-cde241146b61"
      },
      "source": [
        "print(cv_xgb.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 2, 'verbosity': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcOFnYmmhLoH"
      },
      "source": [
        "print(cv_xgb.best_params_)\r\n",
        "#Best Parameters : {learning_rate : 0.1, max_depth: 4, min_child_weight: 2, verbosity: 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ7BXSUXhdwK"
      },
      "source": [
        "Optimized Model with Best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klTo7cPkhWAx",
        "outputId": "7b264131-d21d-46f1-c44a-749f06ef949f"
      },
      "source": [
        "# clf = XGBClassifier(learning_rate=0.5, max_depth=3, gamma= 0.1, min_child_weight=5, verbosity=3)\r\n",
        "clf = XGBClassifier(learning_rate=0.1, max_depth=4, verbosity=1, min_child_weight=2)\r\n",
        "clf.fit(x_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
              "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12EVgE3aho1S",
        "outputId": "1cd38d71-0fd2-46ab-bf31-b3ef499a44b9"
      },
      "source": [
        "prediction = clf.predict(x_test_tfidf)\r\n",
        "\r\n",
        "acc = accuracy_score(y_test, prediction).round(4)\r\n",
        "print(\"Accuracy using TF-IDF is: {}%\".format(acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using TF-IDF is: 81.26%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}