{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FILE_PATH': 'cleaned_incidents1.csv'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'FILE_PATH': 'cleaned_incidents1.csv'\n",
    "    }\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import string\n",
    "    import re\n",
    "    from time import time\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import texthero as hero\n",
    "    from texthero import preprocessing\n",
    "    from gensim.models import Word2Vec\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    import warnings\n",
    "except(ImportError):\n",
    "    print(f'Import Error: {ImportError}')\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# set seeds for reproducability\n",
    "from numpy.random import seed\n",
    "seed(500)\n",
    "\n",
    "# global configurations\n",
    "pd.set_option(\"display.max_colwidth\", -1) # show larger text in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- select features\n",
    "- drop missing values\n",
    "- combine selected features into one\n",
    "'''\n",
    "def data(df):\n",
    "    new_df = df[['EventDescription', 'FailedAssets', 'IncidentCause', 'IncidentConsequence', 'IncidentType', 'Status', 'WeatherStation', 'Category']]\n",
    "    new_df.dropna(axis=0, inplace=True)\n",
    "    features = new_df['EventDescription'] +' ' + new_df['IncidentCause'] + ' '+ new_df['IncidentConsequence']\n",
    "    target = new_df['Category']\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataset = pd.read_csv(config['FILE_PATH'])\n",
    "\n",
    "# get features and target\n",
    "features, target = data(dataset)\n",
    "\n",
    "# Text Cleaning and Pre-processing\n",
    "def preprocess_text():\n",
    "    # cleaning steps\n",
    "    cleaning_pipeline = [\n",
    "        preprocessing.fillna,\n",
    "        preprocessing.lowercase,\n",
    "        preprocessing.remove_whitespace,\n",
    "        preprocessing.remove_punctuation,\n",
    "        preprocessing.remove_urls,\n",
    "        preprocessing.remove_brackets,\n",
    "        preprocessing.remove_stopwords,\n",
    "        preprocessing.remove_digits,\n",
    "        preprocessing.remove_angle_brackets,\n",
    "        preprocessing.remove_curly_brackets,\n",
    "        preprocessing.stem\n",
    "        #preprocessing.tokenize\n",
    "    ]\n",
    "\n",
    "    # apply pipeline to text\n",
    "    clean_text = features.pipe(hero.clean, cleaning_pipeline)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       nearbi custom report spark electr line locat attend crew found high voltag abc conductor fault midspan result ground fire approx sqm report injuri hvabc cabl fault midspan grassfir                                                                                                                                                                                                               \n",
       "1       contractor report contact earth cabl excav trench locat arriv crew found contractor denni jame ph dig trench contact earth cabl caus damag cabl report injuri third parti properti damag contractor contact earth conductor go zone contact                                                                                                                                                        \n",
       "2       field crew attend outag found 22kv conductor broken due rust connect sleev fallen ground one end remain aliv due high imped backfe downlin transform wind protect oper report injuri third parti properti damag conductor broke due rust serious risk public safeti e g live conductor ground live asset access unauthoris person                                                                  \n",
       "3       interfer vandal substat unknown third parti use unknown object interfer two hv fuse blew indoor substat littl bank kingsway indoor substat affect also secur park rear bank street theft vandal ticket machin conjunct substat interfer vandal vandal loss suppli damag network asset                                                                                                              \n",
       "4       nearbi custom report high load pull wire locat arriv crew found lv servic cabl contact unknown vehicl break cabl fell ground report injuri third parti properti damag follow repair cabl measur 3m kerb unknown high load contact lv servic cabl go zone contact damag network asset                                                                                                               \n",
       "                                                                                                                                                ...                                                                                                                                                                                                                                                        \n",
       "6499    report came ue fmb spark st kilda st brighton arriv crew identifi fire damag folcb pole lis eio call assess caus like caus determin eio earth defect within custom instal eio issu defect st kilda st plant equip                                                                                                                                                                                  \n",
       "6500    report receiv resid advis crane made contact powerlin power wire appear fine crane longer contact upon arriv fault crew found crane driver metcalf crane servic made contact 12st swer overhead conductor lis lis move gantri equip associ moorabool windfarm project crane taken away site test fire report injuri crane struck line go zone contact damag network asset                          \n",
       "6501    report receiv pole fire incid locat arriv crew found top burnt swer pole fire extinguish ground fire report injuri third parti properti damag excess leakag current pole top fire                                                                                                                                                                                                                  \n",
       "6502    custom call report tractor hit wire brought ground arriv incid locat crew found tractor rego xv 99ce tow larg roller around paddock turn sharpli contact pole roller caus break fall 22kv hv singl phase conductor fell onto tractor caus protect oper isol suppli tractor driver exit vehicl crew arriv report receiv shock injur report damag fire injuri farm equip hit pole damag network asset\n",
       "6503    concret electr cover outsid front hous gave client dog electr shock rain investig shock livestock pet companion anim                                                                                                                                                                                                                                                                               \n",
       "Length: 6488, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check processed text\n",
    "clean_text = preprocess_text()\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4866,), (1622,), (4866,), (1622,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(clean_text, target, random_state=0, test_size=0.25, shuffle=True)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# feature extraction methods\n",
    "# tfidf\n",
    "def tfidf():\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', max_features=1000)\n",
    "    vectorizer.fit(clean_text)\n",
    "    train_tfidf = vectorizer.transform(x_train)\n",
    "    test_tfidf = vectorizer.transform(x_test)\n",
    "    return train_tfidf, test_tfidf\n",
    "\n",
    "# bow\n",
    "def bow():\n",
    "    count_vectorizer = CountVectorizer(analyzer='word', max_features=1000)\n",
    "    count_vectorizer.fit(clean_text)\n",
    "    train_bow = count_vectorizer.transform(x_train)\n",
    "    test_bow = count_vectorizer.transform(x_test)\n",
    "    return train_bow, test_bow\n",
    "\n",
    "# bigrams\n",
    "def bigrams():\n",
    "    bigram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2), max_features=1000)\n",
    "    bigram_vectorizer.fit(clean_text)\n",
    "    train_bigram = bigram_vectorizer.transform(x_train)\n",
    "    test_bigram = bigram_vectorizer.transform(x_test)\n",
    "    return train_bigram, test_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get features\n",
    "train_tfidf, test_tfidf = tfidf()\n",
    "train_tfidf.shape, test_tfidf.shape\n",
    "\n",
    "train_bigram, test_bigram = bigrams()\n",
    "\n",
    "train_bow, test_bow = bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8329223181257707\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    AF Other       0.53      0.53      0.53        91\n",
      "      Animal       0.90      0.88      0.89        75\n",
      "   Conductor       0.62      0.41      0.49        39\n",
      "  Connection       0.75      0.90      0.82       227\n",
      "    Crossarm       0.84      0.94      0.89       116\n",
      "      Dug up       0.92      0.93      0.92        99\n",
      "        Fuse       0.93      0.87      0.90       105\n",
      "Installation       0.00      0.00      0.00         7\n",
      "   Lightning       0.90      0.82      0.86        33\n",
      "    OH Cable       0.66      0.53      0.58        59\n",
      "       Other       0.87      0.88      0.87       315\n",
      "        Pole       0.82      0.63      0.71        84\n",
      "       Trees       0.90      0.88      0.89       138\n",
      "    UG Cable       0.00      0.00      0.00         6\n",
      "     Vehicle       0.92      0.95      0.93       228\n",
      "\n",
      "    accuracy                           0.83      1622\n",
      "   macro avg       0.70      0.68      0.69      1622\n",
      "weighted avg       0.83      0.83      0.83      1622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD classifier with TFIDF\n",
    "rf = SGDClassifier(random_state=0, alpha=0.0001, loss='hinge', max_iter=100, penalty='l2', n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "rf.fit(train_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'loss': 'log', 'max_iter': 500, 'penalty': 'l1'}\n",
      "0.82881390985774\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'penalty' : ['l2','l1', 'elasticnet'],\n",
    "    'alpha' : [0.0001, 0.00001, 0.0005],\n",
    "    'max_iter': [500, 800, 1000, 1200]\n",
    "\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=SGDClassifier(random_state=0),\n",
    "                      param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "CV_rfc.fit(train_tfidf, y_train)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286066584463625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD classifier with TFIDF\n",
    "rf = SGDClassifier(random_state=0, n_jobs=-1, loss='log', max_iter=500, penalty='l1')\n",
    "\n",
    "# fit\n",
    "rf.fit(train_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get features\n",
    "train_tfidf, test_tfidf = tfidf()\n",
    "train_tfidf.shape, test_tfidf.shape\n",
    "\n",
    "train_bigram, test_bigram = bigrams()\n",
    "\n",
    "train_bow, test_bow = bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (15090, 1000)\n",
      "Crossarm        1006\n",
      "Lightning       1006\n",
      "Connection      1006\n",
      "Conductor       1006\n",
      "UG Cable        1006\n",
      "Installation    1006\n",
      "Fuse            1006\n",
      "Pole            1006\n",
      "OH Cable        1006\n",
      "Vehicle         1006\n",
      "Animal          1006\n",
      "AF Other        1006\n",
      "Dug up          1006\n",
      "Other           1006\n",
      "Trees           1006\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(random_state=0,n_jobs=-1,k_neighbors=5)\n",
    "train_tfidf, y_train = oversample.fit_resample(train_tfidf, y_train)\n",
    "print(f'Shape: {train_tfidf.shape}')\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8242909987669543"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD classifier with TFIDF\n",
    "sgd = SGDClassifier(random_state=0, max_iter=5000, n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "sgd.fit(train_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "0.9380384360503644\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log'],\n",
    "    'penalty' : ['l2','l1', 'elasticnet'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [1000, 2000, 5000, 8000]\n",
    "\n",
    "}\n",
    "CV_sgd = GridSearchCV(estimator=SGDClassifier(random_state=0),\n",
    "                      param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "CV_sgd.fit(train_tfidf, y_train)\n",
    "print(CV_sgd.best_params_)\n",
    "print(CV_sgd.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8242909987669543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD classifier with TFIDF\n",
    "sgd = SGDClassifier(random_state=0, alpha=0.0001, loss='hinge', max_iter=1000, penalty='l2', n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "sgd.fit(train_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = sgd.predict(test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train proba: [[3.93549788e-02 1.03363528e-04 7.17322352e-04 ... 1.02406432e-04\n",
      "  7.41410394e-06 6.73492518e-05]\n",
      " [9.79981425e-02 2.51615235e-02 6.99433632e-01 ... 2.17490662e-02\n",
      "  3.80493714e-04 3.29265132e-02]\n",
      " [1.91265185e-04 2.19319510e-05 3.19567842e-03 ... 2.90667684e-04\n",
      "  3.83388901e-08 5.99863496e-01]\n",
      " ...\n",
      " [5.11730606e-07 2.38084437e-03 7.91652150e-03 ... 1.87054299e-04\n",
      "  6.09606234e-08 9.86163738e-01]\n",
      " [7.77361729e-04 8.72246761e-05 2.39120853e-02 ... 1.02288938e-03\n",
      "  1.46396934e-06 9.59954806e-01]\n",
      " [2.04419016e-04 2.09317432e-04 8.16809235e-06 ... 3.87167390e-05\n",
      "  5.09346080e-07 9.66785706e-01]]\n",
      "test proba: [[6.18494229e-02 1.38052444e-04 6.39777105e-04 ... 6.65910326e-05\n",
      "  2.09972166e-07 1.44493871e-04]\n",
      " [1.83140188e-03 5.12124968e-06 6.20007466e-04 ... 1.12436293e-04\n",
      "  1.84410891e-08 1.31017611e-03]\n",
      " [2.39895099e-03 1.48623617e-05 2.78145513e-03 ... 7.70815145e-05\n",
      "  2.94837582e-07 9.83379985e-01]\n",
      " ...\n",
      " [4.83044319e-03 1.03379257e-04 8.05992153e-06 ... 1.21942615e-04\n",
      "  1.42677747e-06 2.54453413e-04]\n",
      " [3.46732363e-03 2.33720121e-04 9.71639298e-05 ... 2.71440020e-04\n",
      "  9.75065314e-06 1.57674183e-04]\n",
      " [1.64689853e-03 4.02924464e-04 1.23776349e-02 ... 3.76917401e-04\n",
      "  2.32019219e-06 5.94070585e-04]]\n"
     ]
    }
   ],
   "source": [
    "calibrator = CalibratedClassifierCV(sgd, cv='prefit')\n",
    "sgd=calibrator.fit(train_tfidf, y_train)\n",
    "\n",
    "y_train_pred = sgd.predict_proba(train_tfidf)\n",
    "y_test_pred = sgd.predict_proba(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#saving the model into a package\n",
    "import pickle\n",
    "pickle.dump(sgd, open(\"sgd.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
