{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from collections import OrderedDict\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.pyplot import figure\n",
    "    import string\n",
    "    import texthero as hero\n",
    "    from texthero import preprocessing\n",
    "    import nltk\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "    from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "    from nltk.corpus import wordnet\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    import warnings\n",
    "except(ImportError):\n",
    "    print(f'Import Error: {ImportError}')\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# set seeds for reproducability\n",
    "from numpy.random import seed\n",
    "seed(500)\n",
    "\n",
    "# global configurations\n",
    "pd.set_option(\"display.max_colwidth\", -1) # show larger text in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "try:\n",
    "    df = pd.read_csv('../../cleaned_incidents1.csv')\n",
    "except:\n",
    "    df = pd.read_csv(\"/Users/pradeep/Desktop/ProjectANotebooks/notebooks/cleaned_incidents1.csv\")\n",
    "\n",
    "# drop missing category\n",
    "df = df.dropna(axis=0, subset=['Category'])\n",
    "\n",
    "# factorize category\n",
    "df['category_id'] = df['Category'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ActionTaken', 'Address', 'AssetLabel', 'CauseCommunity',\n       'CauseEnvironment', 'CausePre', 'CauseTechnical', 'CauseWorkP',\n       'ContactType', 'CorrectProtection', 'EventDescription', 'FailedAssets',\n       'FailedExplosion', 'FailedOilFilled', 'FailedOtherAssets',\n       'FailedOtherAssetsOther', 'FeederNumber', 'IncidentCause',\n       'IncidentConsequence', 'IncidentDatetime',\n       'IncidentFireFFactorReportable', 'IncidentFireSeverity', 'IncidentID',\n       'IncidentLocationType', 'IncidentLocationTypeOther', 'IncidentNumber',\n       'IncidentType', 'Lat', 'Long', 'MadeSafe', 'NetworkType', 'Status',\n       'SubmissionID', 'SubmittedDateTimeString', 'Voltage', 'WeatherStation',\n       'Postcode', 'Locality', 'Category', 'category_id'],\n      dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrectProtection                float64\n",
      "FailedExplosion                  int64  \n",
      "FailedOilFilled                  int64  \n",
      "FailedOtherAssets                int64  \n",
      "IncidentFireFFactorReportable    float64\n",
      "IncidentID                       int64  \n",
      "Lat                              float64\n",
      "Long                             float64\n",
      "MadeSafe                         int64  \n",
      "SubmissionID                     int64  \n",
      "Postcode                         float64\n",
      "category_id                      int64  \n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               CorrectProtection  FailedExplosion  \\\nCorrectProtection              1.000000          -0.342556          \nFailedExplosion               -0.342556           1.000000          \nFailedOilFilled               -0.337414           0.981676          \nFailedOtherAssets             -0.341863           0.990239          \nIncidentFireFFactorReportable -0.148627          -0.060582          \nIncidentID                    -0.416294           0.215122          \nLat                           -0.121339           0.221316          \nLong                           0.014758          -0.149428          \nMadeSafe                      -0.081096          -0.130761          \nSubmissionID                  -0.400821           0.186195          \nPostcode                      -0.102839          -0.119462          \ncategory_id                   -0.077354          -0.095899          \n\n                               FailedOilFilled  FailedOtherAssets  \\\nCorrectProtection             -0.337414        -0.341863            \nFailedExplosion                0.981676         0.990239            \nFailedOilFilled                1.000000         0.976934            \nFailedOtherAssets              0.976934         1.000000            \nIncidentFireFFactorReportable -0.061994        -0.059690            \nIncidentID                     0.209143         0.211598            \nLat                            0.216609         0.222168            \nLong                          -0.145090        -0.149923            \nMadeSafe                      -0.128800        -0.129561            \nSubmissionID                   0.181922         0.183428            \nPostcode                      -0.123442        -0.118240            \ncategory_id                   -0.094374        -0.100103            \n\n                               IncidentFireFFactorReportable  IncidentID  \\\nCorrectProtection             -0.148627                      -0.416294     \nFailedExplosion               -0.060582                       0.215122     \nFailedOilFilled               -0.061994                       0.209143     \nFailedOtherAssets             -0.059690                       0.211598     \nIncidentFireFFactorReportable  1.000000                       0.040662     \nIncidentID                     0.040662                       1.000000     \nLat                            0.145878                       0.024937     \nLong                          -0.004229                      -0.011049     \nMadeSafe                       0.039426                       0.086841     \nSubmissionID                   0.063232                       0.974835     \nPostcode                       0.211112                      -0.028798     \ncategory_id                    0.400701                      -0.021569     \n\n                                    Lat      Long  MadeSafe  SubmissionID  \\\nCorrectProtection             -0.121339  0.014758 -0.081096 -0.400821       \nFailedExplosion                0.221316 -0.149428 -0.130761  0.186195       \nFailedOilFilled                0.216609 -0.145090 -0.128800  0.181922       \nFailedOtherAssets              0.222168 -0.149923 -0.129561  0.183428       \nIncidentFireFFactorReportable  0.145878 -0.004229  0.039426  0.063232       \nIncidentID                     0.024937 -0.011049  0.086841  0.974835       \nLat                            1.000000 -0.140321 -0.044830  0.019019       \nLong                          -0.140321  1.000000  0.074967 -0.004007       \nMadeSafe                      -0.044830  0.074967  1.000000  0.099889       \nSubmissionID                   0.019019 -0.004007  0.099889  1.000000       \nPostcode                       0.173324  0.077918  0.111762 -0.018241       \ncategory_id                    0.126489 -0.000068  0.050404 -0.010711       \n\n                               Postcode  category_id  \nCorrectProtection             -0.102839 -0.077354     \nFailedExplosion               -0.119462 -0.095899     \nFailedOilFilled               -0.123442 -0.094374     \nFailedOtherAssets             -0.118240 -0.100103     \nIncidentFireFFactorReportable  0.211112  0.400701     \nIncidentID                    -0.028798 -0.021569     \nLat                            0.173324  0.126489     \nLong                           0.077918 -0.000068     \nMadeSafe                       0.111762  0.050404     \nSubmissionID                  -0.018241 -0.010711     \nPostcode                       1.000000  0.133748     \ncategory_id                    0.133748  1.000000     ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CorrectProtection</th>\n      <th>FailedExplosion</th>\n      <th>FailedOilFilled</th>\n      <th>FailedOtherAssets</th>\n      <th>IncidentFireFFactorReportable</th>\n      <th>IncidentID</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>MadeSafe</th>\n      <th>SubmissionID</th>\n      <th>Postcode</th>\n      <th>category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CorrectProtection</th>\n      <td>1.000000</td>\n      <td>-0.342556</td>\n      <td>-0.337414</td>\n      <td>-0.341863</td>\n      <td>-0.148627</td>\n      <td>-0.416294</td>\n      <td>-0.121339</td>\n      <td>0.014758</td>\n      <td>-0.081096</td>\n      <td>-0.400821</td>\n      <td>-0.102839</td>\n      <td>-0.077354</td>\n    </tr>\n    <tr>\n      <th>FailedExplosion</th>\n      <td>-0.342556</td>\n      <td>1.000000</td>\n      <td>0.981676</td>\n      <td>0.990239</td>\n      <td>-0.060582</td>\n      <td>0.215122</td>\n      <td>0.221316</td>\n      <td>-0.149428</td>\n      <td>-0.130761</td>\n      <td>0.186195</td>\n      <td>-0.119462</td>\n      <td>-0.095899</td>\n    </tr>\n    <tr>\n      <th>FailedOilFilled</th>\n      <td>-0.337414</td>\n      <td>0.981676</td>\n      <td>1.000000</td>\n      <td>0.976934</td>\n      <td>-0.061994</td>\n      <td>0.209143</td>\n      <td>0.216609</td>\n      <td>-0.145090</td>\n      <td>-0.128800</td>\n      <td>0.181922</td>\n      <td>-0.123442</td>\n      <td>-0.094374</td>\n    </tr>\n    <tr>\n      <th>FailedOtherAssets</th>\n      <td>-0.341863</td>\n      <td>0.990239</td>\n      <td>0.976934</td>\n      <td>1.000000</td>\n      <td>-0.059690</td>\n      <td>0.211598</td>\n      <td>0.222168</td>\n      <td>-0.149923</td>\n      <td>-0.129561</td>\n      <td>0.183428</td>\n      <td>-0.118240</td>\n      <td>-0.100103</td>\n    </tr>\n    <tr>\n      <th>IncidentFireFFactorReportable</th>\n      <td>-0.148627</td>\n      <td>-0.060582</td>\n      <td>-0.061994</td>\n      <td>-0.059690</td>\n      <td>1.000000</td>\n      <td>0.040662</td>\n      <td>0.145878</td>\n      <td>-0.004229</td>\n      <td>0.039426</td>\n      <td>0.063232</td>\n      <td>0.211112</td>\n      <td>0.400701</td>\n    </tr>\n    <tr>\n      <th>IncidentID</th>\n      <td>-0.416294</td>\n      <td>0.215122</td>\n      <td>0.209143</td>\n      <td>0.211598</td>\n      <td>0.040662</td>\n      <td>1.000000</td>\n      <td>0.024937</td>\n      <td>-0.011049</td>\n      <td>0.086841</td>\n      <td>0.974835</td>\n      <td>-0.028798</td>\n      <td>-0.021569</td>\n    </tr>\n    <tr>\n      <th>Lat</th>\n      <td>-0.121339</td>\n      <td>0.221316</td>\n      <td>0.216609</td>\n      <td>0.222168</td>\n      <td>0.145878</td>\n      <td>0.024937</td>\n      <td>1.000000</td>\n      <td>-0.140321</td>\n      <td>-0.044830</td>\n      <td>0.019019</td>\n      <td>0.173324</td>\n      <td>0.126489</td>\n    </tr>\n    <tr>\n      <th>Long</th>\n      <td>0.014758</td>\n      <td>-0.149428</td>\n      <td>-0.145090</td>\n      <td>-0.149923</td>\n      <td>-0.004229</td>\n      <td>-0.011049</td>\n      <td>-0.140321</td>\n      <td>1.000000</td>\n      <td>0.074967</td>\n      <td>-0.004007</td>\n      <td>0.077918</td>\n      <td>-0.000068</td>\n    </tr>\n    <tr>\n      <th>MadeSafe</th>\n      <td>-0.081096</td>\n      <td>-0.130761</td>\n      <td>-0.128800</td>\n      <td>-0.129561</td>\n      <td>0.039426</td>\n      <td>0.086841</td>\n      <td>-0.044830</td>\n      <td>0.074967</td>\n      <td>1.000000</td>\n      <td>0.099889</td>\n      <td>0.111762</td>\n      <td>0.050404</td>\n    </tr>\n    <tr>\n      <th>SubmissionID</th>\n      <td>-0.400821</td>\n      <td>0.186195</td>\n      <td>0.181922</td>\n      <td>0.183428</td>\n      <td>0.063232</td>\n      <td>0.974835</td>\n      <td>0.019019</td>\n      <td>-0.004007</td>\n      <td>0.099889</td>\n      <td>1.000000</td>\n      <td>-0.018241</td>\n      <td>-0.010711</td>\n    </tr>\n    <tr>\n      <th>Postcode</th>\n      <td>-0.102839</td>\n      <td>-0.119462</td>\n      <td>-0.123442</td>\n      <td>-0.118240</td>\n      <td>0.211112</td>\n      <td>-0.028798</td>\n      <td>0.173324</td>\n      <td>0.077918</td>\n      <td>0.111762</td>\n      <td>-0.018241</td>\n      <td>1.000000</td>\n      <td>0.133748</td>\n    </tr>\n    <tr>\n      <th>category_id</th>\n      <td>-0.077354</td>\n      <td>-0.095899</td>\n      <td>-0.094374</td>\n      <td>-0.100103</td>\n      <td>0.400701</td>\n      <td>-0.021569</td>\n      <td>0.126489</td>\n      <td>-0.000068</td>\n      <td>0.050404</td>\n      <td>-0.010711</td>\n      <td>0.133748</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Correlation non string columns with category, \n",
    "# we only use moderate columns that have at least moderate relationship with category\n",
    "\n",
    "# get non object types columns\n",
    "df_non_objects = df.select_dtypes(exclude='object')\n",
    "print(df_non_objects.dtypes)\n",
    "\n",
    "# replace with nan with 0, otherwise correlation test won't work\n",
    "df_non_objects = df_non_objects.replace(np.nan, 0, regex=True)\n",
    "df_non_objects.isna().sum()\n",
    "\n",
    "# check correlation of non object columns with category\n",
    "df_non_objects.corr()\n",
    "# result: only IncidentFireFFactorReportable has moderate correlation, the rest are weak, we are going to ignore those columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object type columns: Index(['ActionTaken', 'AssetLabel', 'CauseCommunity', 'CauseEnvironment',\n",
      "       'CausePre', 'CauseTechnical', 'CauseWorkP', 'ContactType',\n",
      "       'EventDescription', 'FailedAssets', 'FailedOtherAssetsOther',\n",
      "       'FeederNumber', 'IncidentCause', 'IncidentConsequence',\n",
      "       'IncidentDatetime', 'IncidentFireSeverity', 'IncidentLocationType',\n",
      "       'IncidentLocationTypeOther', 'IncidentNumber', 'IncidentType',\n",
      "       'NetworkType', 'Status', 'SubmittedDateTimeString', 'Voltage',\n",
      "       'WeatherStation', 'Locality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Now process columns with object types\n",
    "df_objects = df.select_dtypes('object')\n",
    "\n",
    "# Eliminate Address as they can represented by Locality\n",
    "df_objects = df_objects.drop(['Address'], axis=1)\n",
    "\n",
    "# replace missing values\n",
    "df_objects['CauseCommunity'] = df['CauseCommunity'].fillna('Unknown external/community factor')\n",
    "df_objects['CauseEnvironment'] = df['CauseEnvironment'].fillna('Unknown environment factor')\n",
    "df_objects['CauseTechnical'] = df['CauseTechnical'].fillna('Unknown technical factor')\n",
    "df_objects['CauseWorkP'] = df['CauseTechnical'].fillna('Unknown work practice factor')\n",
    "\n",
    "# replace the rest with empty string\n",
    "df_objects = df_objects.replace(np.nan, '', regex=True)\n",
    "\n",
    "# separate target\n",
    "target = df_objects['Category']\n",
    "df_objects = df_objects.drop(['Category'], axis=1)\n",
    "print('object type columns:', df_objects.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Text Cleaning and Pre-processing\n",
    "def preprocess_text(features):\n",
    "    # cleaning steps\n",
    "    cleaning_pipeline = [\n",
    "        preprocessing.fillna,\n",
    "        preprocessing.lowercase,\n",
    "        preprocessing.remove_whitespace,\n",
    "        preprocessing.remove_punctuation,\n",
    "        preprocessing.remove_urls,\n",
    "        preprocessing.remove_brackets,\n",
    "        preprocessing.remove_stopwords,\n",
    "        preprocessing.remove_digits,\n",
    "        preprocessing.remove_angle_brackets,\n",
    "        preprocessing.remove_curly_brackets\n",
    "    ]\n",
    "\n",
    "    # apply pipeline to text\n",
    "    clean_text = features.pipe(hero.clean, cleaning_pipeline)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize with POS Tag\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def get_lematizer(sentence):\n",
    "    clean_text =  (\" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence) if w not in string.punctuation]))\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_columns(df_source):\n",
    "    description = ''\n",
    "    for column in df_objects:\n",
    "        description = df_objects['description'] + ' ' + df_objects[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'light light lighten run run work work work'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test only\n",
    "get_lematizer('light lighting lighten run running work worked working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features from columns\n",
    "df_objects['description'] = ''\n",
    "for column in df_objects:\n",
    "    df_objects['description'] = df_objects['description'] + ' ' + df_objects[column]\n",
    "        \n",
    "# clean the data\n",
    "clean_text = preprocess_text(df_objects['description']) # feature extraction/vectorize\n",
    "clean_text = clean_text.apply(lambda sentence: get_lematizer(sentence))\n",
    "\n",
    "# preparation for feature selection\n",
    "category_id_df = df[['Category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "\n",
    "# vectorize\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2))\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(clean_text).toarray()\n",
    "labels = df.category_id\n",
    "clean_text = tfidf_features\n",
    "\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show which terms related to each category\n",
    "N = 50\n",
    "keywords = []\n",
    "for Category, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(tfidf_features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  keywords_perCategory = unigrams[-N:]\n",
    "  print(\"# '{}':\".format(Category))\n",
    "  print(keywords_perCategory)\n",
    "  keywords = keywords + keywords_perCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keyWords_inColumn(clean_text_column):\n",
    "    cnt = 0\n",
    "    length = len(clean_text_column.index)\n",
    "    for i in range(length) : \n",
    "        words = clean_text_column.iloc[i].split()\n",
    "        for word in words:\n",
    "            if word in keywords:\n",
    "                cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many important words in each column\n",
    "count_df = df_objects.loc[:, df_objects.columns != 'description']\n",
    "counter_dict = {}\n",
    "for column in count_df:\n",
    "    clean_text_column = preprocess_text(count_df[column]) \n",
    "    cnt = count_keyWords_inColumn(clean_text_column)\n",
    "    counter_dict[column] = cnt\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##Experiements##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter_dict = OrderedDict(sorted(counter_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "counter_dict = sorted(counter_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x= [i[0] for i in counter_dict[::-1]]\n",
    "y = [i[1] for i in counter_dict[::-1]]\n",
    "\n",
    "\n",
    "# plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(80,30))\n",
    "plt.style.use('dark_background')\n",
    "plt.title('Feature Selection: Chi2', fontsize=80, fontweight='bold', color='pink')\n",
    "plt.barh( x, y, color='pink')\n",
    "plt.xlabel('Number of relevant words', fontsize=50, fontweight='bold', color='pink')\n",
    "plt.ylabel('Features', fontsize=50, fontweight='bold', color='pink')\n",
    "plt.tick_params(axis='y', labelsize=28)\n",
    "plt.tick_params(axis='x', labelsize=28)\n",
    "\n",
    "plt.yticks(rotation=45)\n",
    "plt.savefig('chi2.png', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on above graph, get top 10 columns\n",
    "columns = list(counter_dict.keys())[:10]\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save selected columns\n",
    "selected_df = df_objects[columns] \n",
    "selected_df['Category'] = target\n",
    "print(selected_df.columns)\n",
    "selected_df.to_csv('processed_dataset_chi2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cols = len(columns)\n",
    "accuracy_df = pd.DataFrame(columns = ['col_names','lr','sgd'])\n",
    "#print(total_cols)\n",
    "for num_of_cols in range(total_cols):\n",
    "    selected_df['description'] = ''\n",
    "    #print('num_of_cols:', num_of_cols)\n",
    "    col_names = ''\n",
    "    for i in range(num_of_cols+1):\n",
    "        col_names = col_names + ' ' + columns[i]\n",
    "        selected_df['description'] = selected_df['description'] + ' ' + selected_df[columns[i]]\n",
    "    \n",
    "    # clean the data\n",
    "    clean_text = preprocess_text(selected_df['description']) \n",
    "\n",
    "    clean_text = tfidf.transform(clean_text).toarray()\n",
    "\n",
    "    # split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(clean_text, target, random_state=0, test_size=0.25, shuffle=True)\n",
    "\n",
    "    #classification - Logistic regression\n",
    "    lr = LogisticRegression(n_jobs=1, C=1e5)\n",
    "    lr.fit(x_train ,y_train)\n",
    "    y_pred = lr.predict(x_test)\n",
    "    lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    #classification - SGD\n",
    "    sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "    sgd.fit(x_train, y_train)\n",
    "    y_pred = sgd.predict(x_test)\n",
    "    sgd_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    new_row = {'col_names':col_names, 'lr':lr_accuracy, 'sgd':sgd_accuracy}\n",
    "    accuracy_df = accuracy_df.append(new_row, ignore_index=True)\n",
    "\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "accuracy_df.to_csv('accuracy_chi2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise accuracy\n",
    "\n",
    "# get from ds if no more in cache\n",
    "accuracy_df = pd.read_csv('accuracy_df.csv')\n",
    "\n",
    "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "x = accuracy_df[['col_id']] + 1\n",
    "y1 = accuracy_df[['lr']]\n",
    "plt.plot(x, y1, label = \"Logistic Regression\")\n",
    "\n",
    "y2 = accuracy_df[['sgd']]\n",
    "plt.plot(x, y2, label = \"Stochastic Gradient Descent\")\n",
    "\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.xticks(x.iloc[:,0])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}