{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'FILE_PATH': '/Users/pradeep/Desktop/ProjectANotebooks/notebooks/processed_dataset.csv'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'FILE_PATH': '/Users/pradeep/Desktop/ProjectANotebooks/notebooks/processed_dataset.csv'\n",
    "    }\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import string\n",
    "    import re\n",
    "    from time import time\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import texthero as hero\n",
    "    from texthero import preprocessing\n",
    "    from gensim.models import Word2Vec\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import StackingClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import warnings\n",
    "except(ImportError):\n",
    "    print(f'Import Error: {ImportError}')\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# set seeds for reproducability\n",
    "from numpy.random import seed\n",
    "seed(500)\n",
    "\n",
    "# global configurations\n",
    "pd.set_option(\"display.max_colwidth\", -1) # show larger text in pandas dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "'''\n",
    "- select features\n",
    "- drop missing values\n",
    "- combine selected features into one\n",
    "'''\n",
    "def data(df):\n",
    "    #new_df = df[['EventDescription', 'FailedAssets', 'IncidentCause', 'IncidentConsequence', 'IncidentType', 'Status', 'WeatherStation', 'Category']]\n",
    "    #new_df.dropna(axis=0, inplace=True)\n",
    "    features = df['EventDescription'] +' ' + df['Address'] + ' '+ df['IncidentCause'] +' ' + df['ActionTaken'] +\\\n",
    "    ' '+ df['FailedAssets'] +' ' + df['Locality']  + ' ' + df['IncidentConsequence'] + ' ' + \\\n",
    "    df['CauseTechnical'] + ' ' + df['CauseTechnical']\n",
    "    target = df['Category']\n",
    "    return features, target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# read csv\n",
    "dataset = pd.read_csv(config['FILE_PATH'])\n",
    "\n",
    "# get features and target\n",
    "features, target = data(dataset)\n",
    "\n",
    "# Text Cleaning and Pre-processing\n",
    "def preprocess_text():\n",
    "    # cleaning steps\n",
    "    cleaning_pipeline = [\n",
    "        preprocessing.fillna,\n",
    "        preprocessing.lowercase,\n",
    "        preprocessing.remove_whitespace,\n",
    "        preprocessing.remove_punctuation,\n",
    "        preprocessing.remove_urls,\n",
    "        preprocessing.remove_brackets,\n",
    "        preprocessing.remove_stopwords,\n",
    "        preprocessing.remove_digits,\n",
    "        preprocessing.remove_angle_brackets,\n",
    "        preprocessing.remove_curly_brackets,\n",
    "        preprocessing.stem\n",
    "        #preprocessing.tokenize\n",
    "    ]\n",
    "\n",
    "    # apply pipeline to text\n",
    "    clean_text = features.pipe(hero.clean, cleaning_pipeline)\n",
    "\n",
    "    return clean_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0       nearbi custom report spark electr line locat attend crew found high voltag abc conductor fault midspan result ground fire approx sqm report injuri para park hendi main road paraparap vic hvabc cabl fault midspan crew isol suppli undertook repair conductor abc paraparap grassfir earth fault earth fault                                                                                                                                                                                                    \n1       contractor report contact earth cabl excav trench locat arriv crew found contractor denni jame ph dig trench contact earth cabl caus damag cabl report injuri third parti properti damag christi road ravenhal vic contractor contact earth conductor crew undertook repair fail asset ravenhal go zone contact leakag leakag                                                                                                                                                                                     \n2       field crew attend outag found 22kv conductor broken due rust connect sleev fallen ground one end remain aliv due high imped backfe downlin transform wind protect oper report injuri third parti properti damag dunbar road peterborough vic conductor broke due rust crew isol suppli undertook repair conductor bare peterborough serious risk public safeti e g live conductor ground live asset access unauthoris person corros corros                                                                        \n3       interfer vandal substat unknown third parti use unknown object interfer two hv fuse blew indoor substat littl bank kingsway indoor substat affect also secur park rear bank street theft vandal ticket machin conjunct substat interfer vandal bank street south melbourn vic vandal crew undertook repair indoor south melbourn loss suppli damag network asset leakag leakag                                                                                                                                    \n4       nearbi custom report high load pull wire locat arriv crew found lv servic cabl contact unknown vehicl break cabl fell ground report injuri third parti properti damag follow repair cabl measur 3m kerb wilson road whittington vic unknown high load contact lv servic cabl crew isol suppli undertook repair servic conductor whittington go zone contact damag network asset leakag leakag                                                                                                                     \n                                                                                                                                                                                                    ...                                                                                                                                                                                                                                                                                                                   \n6438    report came ue fmb spark st kilda st brighton arriv crew identifi fire damag folcb pole lis eio call assess caus st kilda street brighton vic like caus determin eio earth defect within custom instal eio issu defect st kilda st crew replac phase folcb pole connect box brighton plant equip earth fault earth fault                                                                                                                                                                                          \n6439    report receiv resid advis crane made contact powerlin power wire appear fine crane longer contact upon arriv fault crew found crane driver metcalf crane servic made contact 12st swer overhead conductor lis lis move gantri equip associ moorabool windfarm project crane taken away site test fire report injuri bank rd mount wallac vic australia crane struck line conductor repair point contact conductor bare mount wallac go zone contact damag network asset leakag leakag                             \n6440    report receiv pole fire incid locat arriv crew found top burnt swer pole fire extinguish ground fire report injuri third parti properti damag vallanc road ouyen vic excess leakag current arriv crew isol suppli arrang pole replac pole wood ouyen pole top fire leakag leakag                                                                                                                                                                                                                                  \n6441    custom call report tractor hit wire brought ground arriv incid locat crew found tractor rego xv 99ce tow larg roller around paddock turn sharpli contact pole roller caus break fall 22kv hv singl phase conductor fell onto tractor caus protect oper isol suppli tractor driver exit vehicl crew arriv report receiv shock injur report damag fire injuri ford rd ultima vic australia farm equip hit pole arriv crew isol suppli carri repair conductor bare pole wood ultima damag network asset leakag leakag\n6442    concret electr cover outsid front hous gave client dog electr shock rain dane place wodonga vic investig despatch crew inspector investig repair servic pit network wodonga shock livestock pet companion anim leakag leakag                                                                                                                                                                                                                                                                                      \nLength: 6443, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check processed text\n",
    "clean_text = preprocess_text()\n",
    "clean_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "((4832,), (1611,), (4832,), (1611,))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(clean_text, target, random_state=0, test_size=0.25, shuffle=True)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# feature extraction methods\n",
    "# tfidf\n",
    "def tfidf():\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', max_features=1000)\n",
    "    vectorizer.fit(clean_text)\n",
    "    with open('TFIDF_1000.pickle', 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "    train_tfidf = vectorizer.transform(x_train)\n",
    "    test_tfidf = vectorizer.transform(x_test)\n",
    "    return train_tfidf, test_tfidf\n",
    "\n",
    "# bow\n",
    "def bow():\n",
    "    count_vectorizer = CountVectorizer(analyzer='word', max_features=1000)\n",
    "    count_vectorizer.fit(clean_text)\n",
    "    train_bow = count_vectorizer.transform(x_train)\n",
    "    test_bow = count_vectorizer.transform(x_test)\n",
    "    return train_bow, test_bow\n",
    "\n",
    "# bigrams\n",
    "def bigrams():\n",
    "    bigram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2), max_features=1000)\n",
    "    bigram_vectorizer.fit(clean_text)\n",
    "    train_bigram = bigram_vectorizer.transform(x_train)\n",
    "    test_bigram = bigram_vectorizer.transform(x_test)\n",
    "    return train_bigram, test_bigram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# get features\n",
    "train_tfidf, test_tfidf = tfidf()\n",
    "train_tfidf.shape, test_tfidf.shape\n",
    "\n",
    "train_bigram, test_bigram = bigrams()\n",
    "\n",
    "train_bow, test_bow = bow()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=0,n_jobs=-1,k_neighbors=5)\n",
    "train_tfidf, y_train = oversample.fit_resample(train_tfidf, y_train)\n",
    "print(f'Shape: {train_tfidf.shape}')\n",
    "print(y_train.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7920546244568591"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest classifier with TFIDF\n",
    "rf = MLPClassifier(random_state=0)\n",
    "\n",
    "# fit\n",
    "rf.fit(train_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8218497827436375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AF Other       0.61      0.56      0.58        93\n",
      "      Animal       0.95      0.85      0.90        67\n",
      "   Conductor       0.35      0.50      0.41        34\n",
      "  Connection       0.73      0.88      0.80       210\n",
      "    Crossarm       0.89      0.89      0.89       130\n",
      "      Dug up       0.92      0.88      0.90        92\n",
      "        Fuse       0.86      0.81      0.84       107\n",
      "Installation       0.00      0.00      0.00         8\n",
      "   Lightning       0.93      0.66      0.77        41\n",
      "    OH Cable       0.76      0.58      0.66        60\n",
      "       Other       0.87      0.91      0.89       325\n",
      "        Pole       0.59      0.60      0.60        83\n",
      "       Trees       0.95      0.92      0.93       134\n",
      "    UG Cable       0.00      0.00      0.00         6\n",
      "     Vehicle       0.93      0.90      0.91       221\n",
      "\n",
      "    accuracy                           0.82      1611\n",
      "   macro avg       0.69      0.66      0.67      1611\n",
      "weighted avg       0.82      0.82      0.82      1611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "rf = MLPClassifier(random_state=0, alpha=0.01, early_stopping=True,\n",
    "                        hidden_layer_sizes=(500,),\n",
    "                        learning_rate='constant',\n",
    "                        learning_rate_init= 0.001, max_iter= 100\n",
    "                        )\n",
    "\n",
    "# fit\n",
    "rf.fit(train_tfidf, y_train)\n",
    "\n",
    "#with open('random_forest.pickle', 'wb') as f:\n",
    "   # pickle.dump(rf, f)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}